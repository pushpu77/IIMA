{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3b3d389",
      "metadata": {
        "id": "f3b3d389"
      },
      "outputs": [],
      "source": [
        "#!pip install numpy\n",
        "#!pip install pandas\n",
        "# #!pip install matplotlib\n",
        "# !pip install transformers\n",
        "# !pip install finbert-embedding transformers\n",
        "# !pip install swifter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e32e07c",
      "metadata": {
        "id": "8e32e07c"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "import swifter\n",
        "# Imports for reading input directory\n",
        "import os\n",
        "#import torch\n",
        "#import shutil\n",
        "#the encoding detection and handling logic using the chardet\n",
        "import chardet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebd62394",
      "metadata": {
        "id": "ebd62394"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c14c017",
      "metadata": {
        "id": "4c14c017"
      },
      "outputs": [],
      "source": [
        "print(\"bert\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99e75f16",
      "metadata": {
        "id": "99e75f16"
      },
      "outputs": [],
      "source": [
        "##########################################################################\n",
        "# numlabels is set to 2 as Bert can classify using 3 sentiments:         #\n",
        "# positive, negative and neutral                                         #\n",
        "##########################################################################\n",
        "model_name = \"ProsusAI/finbert\"\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c04ab67d",
      "metadata": {
        "id": "c04ab67d"
      },
      "outputs": [],
      "source": [
        "##########################################################################\n",
        "# Preprocess function : This piece of code forms a embedded form for     #\n",
        "# the input text                                                         #\n",
        "##########################################################################\n",
        "def preprocess_text(text):\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=512,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed18c526",
      "metadata": {
        "id": "ed18c526"
      },
      "outputs": [],
      "source": [
        "##########################################################################\n",
        "# This piece of code takes text as input and finds the                   #\n",
        "# softmax probablitites (from logits) for positive and negative class    #\n",
        "##########################################################################\n",
        "def get_sentiment_scores(text):\n",
        "    inputs = preprocess_text(text)\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    probabilities = logits.softmax(dim=1)\n",
        "    return probabilities.tolist()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff99f84a",
      "metadata": {
        "id": "ff99f84a"
      },
      "outputs": [],
      "source": [
        "#def process_csv_files(folder_path):\n",
        "    #Read the csv file from the folder\n",
        "   # data = pd.read_csv(folder_path + 'cleaned_text.csv')\n",
        "    #Apply get_sentiment_scores function for sentiment scores on the csv file text data (here column: 'Cleaned Text')\n",
        "   # data[['Positive', 'Neutral', 'Negative']] = data['Cleaned Text'].swifter.apply(lambda x: pd.Series(get_sentiment_scores(x)))\n",
        "    #Drop the text variable; Keep only the scores and id\n",
        "    #data_sub = data.drop('Cleaned Text',axis =1)\n",
        "    # return the smaller dataset\n",
        "    #return data_sub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "198994d1",
      "metadata": {
        "id": "198994d1"
      },
      "outputs": [],
      "source": [
        "##############################################################\n",
        "# This fuction reads the input directory with parsed data    #\n",
        "# It captures the accession number                           #\n",
        "# And calculates the sentiment score of the text             #\n",
        "# Finally creates a dataframe for same                       #\n",
        "##############################################################\n",
        "#preprocess_text_file system\n",
        "def process_text_files(folder_path):\n",
        "    #Define the results as empty array\n",
        "    results = []\n",
        "    count=1\n",
        "    # Iterate over files in the input directory\n",
        "    for filename in os.listdir(folder_path):\n",
        "        #Find the filepath\n",
        "        if filename.endswith(\".txt\"):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        if os.path.isfile(file_path):  # Check if the path is a file\n",
        "            with open(file_path, 'rb') as file:\n",
        "                raw_data = file.read()\n",
        "                encoding = chardet.detect(raw_data)['encoding']\n",
        "\n",
        "            try:\n",
        "                text = raw_data.decode(encoding)\n",
        "            except UnicodeDecodeError:\n",
        "                print(f\"Error decoding file: {file_path} with encoding: {encoding}. Skipping...\")\n",
        "                continue\n",
        "            #keeping file name as the identifier\n",
        "            file_id = filename.split('.')[0]\n",
        "\n",
        "            #calculate the sentiments for each text file\n",
        "            print(count)\n",
        "            scores = get_sentiment_scores(text)\n",
        "            count = count+1\n",
        "            #Store results as dictionary\n",
        "            result ={'id':file_id,'Positive':scores[0],'Neutral':scores[1],'Negative':scores[2]}\n",
        "            #Append the results to final results\n",
        "            results.append(result)\n",
        "\n",
        "    #Create dataframe from the results\n",
        "    print('generating dataframe')\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    #return df\n",
        "    return df\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "080452f6",
      "metadata": {
        "id": "080452f6"
      },
      "outputs": [],
      "source": [
        "def generate_csv(df,filename,download_path):\n",
        "    csv_data = df.to_csv(index=False)\n",
        "    csv_file = f\"{filename}.csv\"\n",
        "    # Save the CSV data to a file\n",
        "    with open(f'{download_path}/{csv_file}', 'w') as file:\n",
        "        file.write(csv_data)\n",
        "    #df.to_csv(csv_file,compression='gzip')\n",
        "    print('CSV Generated')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c205d185",
      "metadata": {
        "id": "c205d185"
      },
      "outputs": [],
      "source": [
        "# testing generate_csv function using the process_text_files\n",
        "folder_path= '' #Specify the folder path where all the text files are present\n",
        "output_filename = \"Folder1\"\n",
        "download_path = \"\" #Specify the folder path where you want to save the result\n",
        "df_text = process_text_files(folder_path)\n",
        "#iteration no var\n",
        "generate_csv(df_text,output_filename,download_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}